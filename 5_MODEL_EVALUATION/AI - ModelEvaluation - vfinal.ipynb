{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# This file includes the functions to clean the times and shangai datasets\n",
    "import data_cleaning as dc\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "We need to evaluate the performance of our machine learning models because of two main reason. First to be able to tune them deciding which interventions increase their performance and which ones don't. And secondly to have concrete knowlodge on how accurate they are and therefore to what extent can we trust them. \n",
    "\n",
    "The first insight that we have to incorporate into our thinking of model evaluation is that by no means we can evaluate our model with the data that we used for training. Nowadays algorithms are very sophisticated and therefore prone to overfitting. It is therefore necessary to use new data, unseen by model, for its evaluation. \n",
    "\n",
    "There are two main approaches. One, the most obvious, is to divide the data in a training and test set. We train the model with the train set and we use the test set to evaluate it. It is simple and works well if we have lots of data. However, if data is scarce, then we don't have enough diversity in the data and the evaluation could not be very accurate. \n",
    "\n",
    "The second approach tries to solve this problem of evaluation, as accurate as we can, a model with a limited amount of data. As you can imagine, they consist on using sampling techniques with or without repetition in order to try to \"augment\" the amount of data available. \n",
    "\n",
    "Once we have chosen the best hyperparameters and have the model ready for production, we train it with the whole data and put it in operational use. \n",
    "\n",
    "We are going to look at four different techniques that we can use to split our data and create useful estimates of our models:\n",
    "\n",
    "        1) Train and test sets.\n",
    "        2) K-fold Cross-validation.\n",
    "        3) Leave one-out cross-validation.\n",
    "        4) Repeated random test-train splits.\n",
    "\n",
    "Yes, we will use the Pima Indians onset of diabetes dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pima_indians_cowboy_1889.jpg\">\n",
    "\n",
    "In this exercise we will use one of the traditional Machine Learning dataset, the Pima Indians diabetes dataset.\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "Content\n",
    "The datasets consists of several medical predictor variables and one target variable, <b>Outcome</b>. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "<blockquote>\n",
    "        <ul style=\"list-style-type:square;\">\n",
    "            <li>Pregnancies</li> \n",
    "            <li>Glucose</li>\n",
    "            <li>BloodPressure</li>\n",
    "            <li>SkinThickness</li>\n",
    "            <li>Insulin</li>\n",
    "            <li>BMI</li>\n",
    "            <li>DiabetesPedigreeFunction (scores de likelihood of diabetes based on family history)</li>\n",
    "            <li>Age</li>\n",
    "            <li>Outcome</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
       "3  1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
       "4  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima indians dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"pima-indians-diabetes.data.csv\"\n",
    "names=[\"pregnancies\", \"glucose\", \"pressure\", \"skin\", \"insulin\", \"bmi\", \"pedi\", \"age\", \"outcome\"]\n",
    "p_indians=pd.read_csv(filename, names=names)\n",
    "p_indians.head()\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=p_indians.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "X\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split into Train and Test Sets </h1>\n",
    "\n",
    "A simple idea and also probably the most commonly used approach is to split our data into two sets. Use one for training and the other for testing. Normally a 70% of the data is used for training and 30% for testing, but of course these are arbitrary numbers and anything can be (e.g. 80% - 20% if the dataset is large). \n",
    "\n",
    "The points in favor of this approach is that is simple and fast. It works well when datasets are large but also it is widely used as a first approximation. One important thing that must be taken into account is that the variance of both sets is similar, if not we can encounter unwanted surprises. \n",
    "\n",
    "The downside is that we can have meaninful differences is the differences in variance are high and we that we take an important risk when the amount of data is small. Once the model is in production we may find that its performance has little in common with what we tested because the data that it encounters is really different. \n",
    "\n",
    "The <b> train_test_split </b> module in scikit-learn is the one used for splitting the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.190\n"
     ]
    }
   ],
   "source": [
    "# Split into Train and Test Sets\n",
    "set_printoptions(precision=3)\n",
    "p_indians.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# we need to make it reproducible, so we use a seed for the pseudo-random\n",
    "test_size=0.3\n",
    "seed = 7\n",
    "\n",
    "# the actual split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Let's do the log regresssion\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# Now let's find the accurary with the test split\n",
    "result = model.score(X_test, Y_test)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 1</font>\n",
    "\n",
    "a) Change the distribution between Train and Test Sets. How does it affect accurarcy?\n",
    "<br><br>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest Set size at 10%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mAccuracy 83.117\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 30%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mAccuracy 76.190\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 50%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mAccuracy 77.344\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 70%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mAccuracy 73.606\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 90%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mAccuracy 66.474\u001b[0m\n",
      "\n",
      "The accuracy of the model decreases as we increase the test set size.\n",
      "The reason for this is that the train set is smaller, and hence the model has not been as trained.\n",
      "Therefore, if the model is not as trained, than its accuracy will not be as good.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m\" + \"Test Set size at 10%\" + \"\\033[0m\")\n",
    "\n",
    "# Test set size 10%\n",
    "\n",
    "test_size=0.1\n",
    "seed = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print('\\033[91m' + f'Accuracy {result*100:5.3f}' + \"\\033[0m\")\n",
    "print()\n",
    "\n",
    "print(\"\\033[1m\" + \"Test Set size at 30%\" + \"\\033[0m\")\n",
    "\n",
    "# Test set size 30%\n",
    "\n",
    "test_size=0.3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print('\\033[91m' + f'Accuracy {result*100:5.3f}' + \"\\033[0m\")\n",
    "print()\n",
    "\n",
    "print(\"\\033[1m\" + \"Test Set size at 50%\" + \"\\033[0m\")\n",
    "\n",
    "# Test set size 50%\n",
    "\n",
    "test_size=0.5\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print('\\033[91m' + f'Accuracy {result*100:5.3f}' + \"\\033[0m\")\n",
    "print()\n",
    "\n",
    "print(\"\\033[1m\" + \"Test Set size at 70%\" + \"\\033[0m\")\n",
    "\n",
    "# Test set size 70%\n",
    "\n",
    "test_size=0.7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print('\\033[91m' + f'Accuracy {result*100:5.3f}' + \"\\033[0m\")\n",
    "print()\n",
    "\n",
    "print(\"\\033[1m\" + \"Test Set size at 90%\" + \"\\033[0m\")\n",
    "\n",
    "# Test set size 90%\n",
    "\n",
    "test_size=0.9\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print('\\033[91m' + f'Accuracy {result*100:5.3f}' + \"\\033[0m\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"The accuracy of the model decreases as we increase the test set size.\")\n",
    "print(\"The reason for this is that the train set is smaller, and hence the model has not been as trained.\")\n",
    "print(\"Therefore, if the model is not as trained, than its accuracy will not be as good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=k-fold.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>K-fold Cross-Validation</h1>\n",
    "\n",
    "The objective of k-fold cross-validation is to reduce the variance that we encounter when using the train-test split approach. \n",
    "\n",
    "In this approach the available data is divided into k splits that are called folds (3, 5, 10 are common). We train and test the model k times. Each time we use k-1 folds for training and one fold for testing. Once we finish we use the mean of the evaluation measure together with its standard deviation as performance measure. \n",
    "\n",
    "Obviously the dataset must be large enough to accommodate the process. \n",
    "\n",
    "K-Fold Cross Validation uses the <b>KFold </b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, k-fold 10 - Accuracy 77.086% (5.091%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.831, 0.714, 0.714, 0.779, 0.792, 0.766, 0.688, 0.857, 0.803,\n",
       "       0.763])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# KFold\n",
    "splits=10\n",
    "kfold=KFold(n_splits=splits, random_state=7, shuffle = True)\n",
    "\n",
    "# Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Obtain the performance measure - accuracy\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(f'Logistic regression, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Leave One Out Cross-Validation</h1>\n",
    "\n",
    "What will happen if we take k-fold to the extreme? In this case we will have as many folds as points, so k will be equal to the number of points and the prediction will be done each time for the one point left. \n",
    "\n",
    "This is an effort to make the most reasonable estimate possible given a dataset, it's called leave one out cross validation. \n",
    "\n",
    "Obviously you pay a penalty in terms of computational expense and the standard deviation has more variance than with k-fold. \n",
    "\n",
    "For Leave One Out Cross-Validation you use the <b>LeaveOneOut</b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression, Leave one out - Accuracy 76.823% (42.196%)\n"
     ]
    }
   ],
   "source": [
    "# Leave one out cross-validation \n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "# Leave one out cross-validation\n",
    "loo=LeaveOneOut()\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#  performance\n",
    "results = cross_val_score(model, X, Y, cv=loo)\n",
    "\n",
    "print(f'Logistic regression, Leave one out - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Repeated Random Test-Train Splits </h1>\n",
    "\n",
    "Another approach is to apply repeatedly a train-test split. This way takes advantage of the train-test speed and the reduction of variance of cross validation at the same time. \n",
    "\n",
    "A down side of the method is that we are including much of the same data, therefore results even if they look very nice, may not be realistic.\n",
    "\n",
    "For Repeated Random Test-Train Splits you use the <b>ShuffleSplit</b> class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Regression - Repeated Test-Train 10 - Accuracy 76.970% 1.366%\n"
     ]
    }
   ],
   "source": [
    "# Repeated Random Test-Train Splits\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "nrepeat=10\n",
    "test_size=0.3\n",
    "seed=7\n",
    "\n",
    "shuffle=ShuffleSplit(n_splits=nrepeat, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "res = cross_val_score(model, X, Y, cv=shuffle)\n",
    "\n",
    "print(f'Log Regression - Repeated Test-Train {nrepeat:d} - Accuracy {res.mean()*100:5.3f}% {res.std()*100:5.3f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Which one to use and When? </h1>\n",
    "\n",
    "First things first. K-fold is the gold-standard, if you are doing any serious work or presenting results to a digital educated audiende, please use k-fold and you'll avoid problems. \n",
    "\n",
    "Train and Test is ok, and it is used for common quick & dirty work. As you have observed in the exercices if the dataset is moderately large, the differences are small. Certainly you avoid surprises with repeatedly using train-test or much better k-fold and your last model should be evaluated always this way, but train and test split is ok for model selection and hyperparameter tunning. \n",
    "\n",
    "What about the rest? In all these techniques you try to balance accuracy in the estimated performance, evaluation speed and dataset size, they correspond to different bets in this balance. \n",
    "\n",
    "You don't know what to do ... The staple is k-fold with 10-cross-validation, start there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 2</font>\n",
    "\n",
    "a) Using the Shangai Data and log regression for top-10, top-50 and top-100 evaluate the models with train-test split and k-fold-10.\n",
    "<br><br>\n",
    "b) Same for the data of the Times ranking. \n",
    "<br><br>\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test\n",
    "\n",
    "def train_test(size, X, Y):  \n",
    "    \n",
    "    print(\"\\033[1m\" + \"Test Set size at \" + str(size * 100) + \"%\" + \"\\033[0m\")\n",
    "\n",
    "    seed = 7\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=size, random_state=seed)\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X_train,Y_train)\n",
    "    result = model.score(X_test, Y_test)\n",
    "    print()\n",
    "    print('\\033[91m' + f'Accuracy {result*100:5.3f}' + \"\\033[0m\")\n",
    "    print()\n",
    "    return model.fit(X_train,Y_train)\n",
    "    \n",
    "    \n",
    "def kfold(n, X, Y):\n",
    "    \n",
    "    splits = n\n",
    "    kfold = KFold(n_splits=splits, random_state=7, shuffle = True)\n",
    "\n",
    "    # Logistic regression\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    # Obtain the performance measure - accuracy\n",
    "    results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "    print(f'Logistic regression, k-fold {splits:d} - Accuracy {results.mean()*100:5.3f}% ({results.std()*100:5.3f}%)')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning shangai dataset\n",
    "\n",
    "shan_10 = dc.shangai_clean(10).values\n",
    "shan_50 = dc.shangai_clean(50).values\n",
    "shan_100 = dc.shangai_clean(100).values\n",
    "\n",
    "shan_x10 = shan_10[:,0:6]\n",
    "shan_y10 = shan_10[:,6]\n",
    "\n",
    "shan_x50 = shan_50[:,0:6]\n",
    "shan_y50 = shan_50[:,6]\n",
    "\n",
    "shan_x100 = shan_100[:,0:6]\n",
    "shan_y100 = shan_100[:,6]\n",
    "\n",
    "times_10 = dc.times_clean(10).values\n",
    "times_50 = dc.times_clean(50).values\n",
    "times_100 = dc.times_clean(100).values\n",
    "\n",
    "times_x10 = times_10[:,0:9]\n",
    "times_y10 = times_10[:,9]\n",
    "\n",
    "times_x50 = times_50[:,0:9]\n",
    "times_y50 = times_50[:,9]\n",
    "\n",
    "times_x100 = times_100[:,0:9]\n",
    "times_y100 = times_100[:,9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShangai training dataset\u001b[0m\n",
      "\n",
      "\u001b[1mShangai top-10\n",
      "\n",
      "\u001b[1mTest Set size at 30.0%\u001b[0m\n",
      "\n",
      "\u001b[91mAccuracy 99.333\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mShangai top-50\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 30.0%\u001b[0m\n",
      "\n",
      "\u001b[91mAccuracy 96.667\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mShangai top-100\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 30.0%\u001b[0m\n",
      "\n",
      "\u001b[91mAccuracy 96.000\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTimes training dataset\u001b[0m\n",
      "\n",
      "\u001b[1mTimes top-10\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 30.0%\u001b[0m\n",
      "\n",
      "\u001b[91mAccuracy 99.052\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTimes top-50\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 30.0%\u001b[0m\n",
      "\n",
      "\u001b[91mAccuracy 96.209\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTimes top-100\u001b[0m\n",
      "\n",
      "\u001b[1mTest Set size at 30.0%\u001b[0m\n",
      "\n",
      "\u001b[91mAccuracy 97.156\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1m\" + \"Shangai training dataset\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Shangai top-10\")\n",
    "print(\"\")\n",
    "\n",
    "train_test(0.3, shan_x10, shan_y10)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Shangai top-50\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "\n",
    "train_test(0.3, shan_x50, shan_y50)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Shangai top-100\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "\n",
    "train_test(0.3, shan_x100, shan_y100)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Times training dataset\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Times top-10\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "\n",
    "train_test(0.3, times_x10, times_y10)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Times top-50\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "\n",
    "train_test(0.3, times_x50, times_y50)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Times top-100\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "\n",
    "train_test(0.3, times_x100, times_y100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShangai kfold cross-validation\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTop 10\u001b[0m\n",
      "\n",
      "Logistic regression, k-fold 10 - Accuracy 98.792% (1.332%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98, 1.  , 1.  , 1.  , 1.  , 0.96, 0.98, 1.  , 0.98, 0.98])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 50\u001b[0m\n",
      "\n",
      "Logistic regression, k-fold 10 - Accuracy 97.792% (1.076%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98, 0.98, 0.98, 1.  , 0.98, 0.98, 0.96, 0.96, 0.98, 0.98])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 100\u001b[0m\n",
      "\n",
      "Logistic regression, k-fold 10 - Accuracy 95.388% (2.685%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96 , 0.98 , 0.98 , 0.9  , 0.94 , 0.98 , 0.94 , 0.92 , 0.98 ,\n",
       "       0.959])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTimes kfold cross-validation\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTop 10\u001b[0m\n",
      "\n",
      "Logistic regression, k-fold 10 - Accuracy 98.861% (1.534%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.972, 1.   , 1.   , 0.986, 0.971, 1.   , 0.957, 1.   , 1.   ,\n",
       "       1.   ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 50\u001b[0m\n",
      "\n",
      "Logistic regression, k-fold 10 - Accuracy 97.439% (1.652%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.986, 0.944, 0.986, 0.986, 0.971, 1.   , 0.957, 0.971, 0.957,\n",
       "       0.986])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 100\u001b[0m\n",
      "\n",
      "Logistic regression, k-fold 10 - Accuracy 95.151% (2.576%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.986, 0.958, 0.971, 0.957, 0.943, 0.943, 0.886, 0.943, 0.971,\n",
       "       0.957])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1m\" + \"Shangai kfold cross-validation\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Top 10\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "kfold(10, shan_x10, shan_y10)\n",
    "print(\"\\033[1m\" + \"Top 50\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "kfold(10, shan_x50, shan_y50)\n",
    "print(\"\\033[1m\" + \"Top 100\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "kfold(10, shan_x100, shan_y100)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"\\033[1m\" + \"Times kfold cross-validation\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"\\033[1m\" + \"Top 10\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "kfold(10, times_x10, times_y10)\n",
    "print(\"\\033[1m\" + \"Top 50\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "kfold(10, times_x50, times_y50)\n",
    "print(\"\\033[1m\" + \"Top 100\" + \"\\033[0m\")\n",
    "print(\"\")\n",
    "kfold(10, times_x100, times_y100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
