{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Features in University Rankings\n",
    "\n",
    "For this project, three different approached will be explored to determine the most relevant features for a classification machine-learning model.\n",
    "\n",
    "1. Univariate Analysis\n",
    "2. Recursive Feature Elimination\n",
    "3. Tree Classifier\n",
    "\n",
    "The data for this project was obtainted from Kaggle, in concrete from the World University Rankings Competition https://www.kaggle.com/mylesoneill/world-university-rankings\n",
    "\n",
    "Two different datasets are available from this link, the Shangai and Times rankings. We want select features for a model which can classify whether a university ranks as top 50 in the rankings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the data, the appropiate modules must be imported first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the data needs to be cleaned. I decided to use a function to clean the data to add one parameter: whether we want to investigate the top 50, top 100 or top 10. The function is also stored on a separate file (using the magic function %%) to be easily imported into other notebooks if needed.\n",
    "\n",
    "The function below is used to clean the Shangai dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_cleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_cleaning.py\n",
    "\n",
    "# Import again so it is saved on the file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Clean shangai dataset function\n",
    "\n",
    "def shangai_clean(x):\n",
    "    \n",
    "    # Read excel file and sort by total score\n",
    "    shangai = pd.read_excel(\"shanghaiData.xlsx\").sort_values(by = \"total_score\", ascending = False)\n",
    "        \n",
    "    # Filter by the latest year\n",
    "    shangai = shangai[shangai[\"year\"] == shangai[\"year\"].max()]\n",
    "    \n",
    "    # Simplify dataframe with only explanatory variables and drop null values\n",
    "    shangai.drop([\"world_rank\", \"university_name\", \"national_rank\", \"year\", \"total_score\"], axis = 1, inplace = True)\n",
    "    \n",
    "    # Drop null values\n",
    "    shangai.dropna(inplace = True)\n",
    "\n",
    "    # Code the top 50 universities\n",
    "    array_ref = (np.arange(len(shangai)) < x)\n",
    "    shangai[\"top_50\"] = array_ref\n",
    "    code = {True:1.0, False:0.0}\n",
    "    shangai[\"top_50\"] = shangai[\"top_50\"].map(code)\n",
    "    \n",
    "    # Return the array\n",
    "    return shangai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the times dataset, we will be appending the function to the previous file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to data_cleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a data_cleaning.py\n",
    "\n",
    "# Clean the times dataset. Here we dont need to import the modules again, since we are appending the function to the previous file \n",
    "\n",
    "def times_clean(a):\n",
    "    \n",
    "    # Read the csv file and sort by total score ind descending order\n",
    "    times = pd.read_csv(\"timesData.csv\").sort_values(by = \"total_score\", ascending = False)\n",
    "    \n",
    "    # Drop null values from total score\n",
    "    times[\"total_score\"] = pd.to_numeric(times[\"total_score\"], errors = \"coerce\")\n",
    "    \n",
    "    # Filter by the latest year\n",
    "    times = times[times[\"year\"] == 2016] \n",
    "            \n",
    "    # Simplify the table by dropping non explanatory variables\n",
    "    times.drop([\"world_rank\", \"university_name\", \"country\", \"year\", \"total_score\"], axis = 1, inplace = True)\n",
    "    \n",
    "    # Times drop null values\n",
    "    times.dropna(inplace = True)\n",
    "\n",
    "    # Convert all other columns to float type\n",
    "    times[\"international\"] = pd.to_numeric(times[\"international\"], errors = \"coerce\")\n",
    "    times[\"income\"] = pd.to_numeric(times[\"income\"], errors = \"coerce\") \n",
    "    times[\"female_male_ratio\"] = pd.to_numeric(times[\"female_male_ratio\"].apply(lambda d: d.split(\" : \")[0]), errors = \"coerce\")\n",
    "    times[\"international_students\"] = pd.to_numeric(times[\"international_students\"].apply(lambda d: d.split(\"%\")[0]), errors = \"coerce\")\n",
    "    \n",
    "    student_list = []\n",
    "    \n",
    "    for x in range(len(times)):\n",
    "        student_value = times[\"num_students\"].iloc[x].replace(\",\",\".\")\n",
    "        student_list.append(student_value)\n",
    "        \n",
    "    times[\"num_students\"] = pd.to_numeric(student_list, errors = \"coerce\")\n",
    "    \n",
    "    # Drop null values once again after converting all other columns to float\n",
    "    times.dropna(inplace = True)\n",
    "    \n",
    "    # Add a new column with the actual ranking\n",
    "    array_ref = (np.arange(len(times)) < a)\n",
    "    times[\"top_50\"] = array_ref\n",
    "    code = {True:1.0, False:0.0}\n",
    "    times[\"top_50\"] = times[\"top_50\"].map(code)\n",
    "    \n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature selection, we need to separate the x and y in each dataset. The y will be the dummy variable indicating whether a university is top 50 or not, and x will be all other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import files with data_cleaning functions\n",
    "\n",
    "import data_cleaning as dc\n",
    "\n",
    "\n",
    "# Shangai and Times top-50 analysis\n",
    "\n",
    "shangai_treat = dc.shangai_clean(50)\n",
    "shan_cols = shangai_treat.columns\n",
    "\n",
    "times_treat = dc.times_clean(50)\n",
    "times_cols = times_treat.columns\n",
    "\n",
    "\n",
    "# Get all values from the table as an array\n",
    "\n",
    "shan_array = shangai_treat.values\n",
    "tim_array = times_treat.values\n",
    "\n",
    "\n",
    "# Separate x and y\n",
    "\n",
    "shan_x = shan_array[:,0:6]\n",
    "shan_y = shan_array[:,6]\n",
    "\n",
    "times_x = tim_array[:,0:9]\n",
    "times_y = tim_array[:,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first feature selection method we will explore will be a univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mUnivariate Analysis\u001b[0m\n",
      "The top features are: hici, alumni, award\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100. , 100. , 100. ],\n",
       "       [ 40.7,  89.6,  80.1],\n",
       "       [ 68.2,  80.7,  60.6],\n",
       "       [ 65.1,  79.4,  66.1],\n",
       "       [ 77.1,  96.6,  50.8]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run univariate analysis\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 \n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "uni = test.fit(shan_x,shan_y)\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Univariate Analysis' '\\033[0m')\n",
    "\n",
    "# Automate column outputs for univariate analysis\n",
    "\n",
    "cols = uni.scores_.argsort()[-3:]\n",
    "print(\"The top features are: \" + shan_cols[cols[0]] + \", \" + shan_cols[cols[1]] + \", \" + shan_cols[cols[2]]) \n",
    "\n",
    "features = uni.transform(shan_x)\n",
    "features[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
