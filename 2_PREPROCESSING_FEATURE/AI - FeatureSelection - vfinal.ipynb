{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duart\\AppData\\Local\\conda\\conda\\envs\\testEnv\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "#sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "The element that has the biggest impact in the quality of your model is data features. You can only include in your model the attributes that you have and if they are not relevant, partially relevant or don't caputre the causality relationships behind the model, or introduce other relationships that correspond to other causes different from the ones that you want to investigate, then you'll have a poor model. \n",
    "\n",
    "Selecting the relevant features that add to your model is therefore of the utmost importance. \n",
    "\n",
    "In this notebook we will deal with four approaches:\n",
    "\n",
    "        1) Univaritate Selection.\n",
    "        2) Recursive feature elimination.\n",
    "        3) PCA - Principal Component Analysis.\n",
    "        4) Estimating feature importance.\n",
    "\n",
    "Feature selection is a process where you select those features in your data that contribute most to the variable of interest. Irrelevant features decrease the accuracy of many models because you try to adjust on noise, this is particularly important in the case of linear models, such as linear and logistic regressions, where all features are always taken into account. Three are the main benefits of feature selection:\n",
    "\n",
    "        1) Reduces overfitting. Less redundant data implies less decisions made on noise. \n",
    "        2) Improves accuracy. Less misleading data results in a more accurate model. \n",
    "        3) Reduces training time. Less data implies faster training. \n",
    "        \n",
    "Scikitlearn has a nice and short article on feature selection where you can learn more https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "Again we will use the Pima Indians onset of diabetes dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Pima_indians_cowboy_1889.jpg\">\n",
    "\n",
    "In this exercise we will use one of the traditional Machine Learning dataset, the Pima Indians diabetes dataset.\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "Content\n",
    "The datasets consists of several medical predictor variables and one target variable, <b>Outcome</b>. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "<blockquote>\n",
    "        <ul style=\"list-style-type:square;\">\n",
    "            <li>Pregnancies</li> \n",
    "            <li>Glucose</li>\n",
    "            <li>BloodPressure</li>\n",
    "            <li>SkinThickness</li>\n",
    "            <li>Insulin</li>\n",
    "            <li>BMI</li>\n",
    "            <li>DiabetesPedigreeFunction (scores de likelihood of diabetes based on family history)</li>\n",
    "            <li>Age</li>\n",
    "            <li>Outcome</li>\n",
    "        </ul>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3      4     5      6     7\n",
       "0  6.0  148.0  72.0  35.0    0.0  33.6  0.627  50.0\n",
       "1  1.0   85.0  66.0  29.0    0.0  26.6  0.351  31.0\n",
       "2  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
       "3  1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
       "4  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pima indians dataset and separate input and output components \n",
    "\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "\n",
    "filename=\"pima-indians-diabetes.data.csv\"\n",
    "names=[\"pregnancies\", \"glucose\", \"pressure\", \"skin\", \"insulin\", \"bmi\", \"pedi\", \"age\", \"outcome\"]\n",
    "p_indians=pd.read_csv(filename, names=names)\n",
    "p_indians.head()\n",
    "\n",
    "# First we separate into input and output components\n",
    "array=p_indians.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "X\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Univariate Selection </h1>\n",
    "\n",
    "One approach is to use statistical tests for example the Pearson Chi-Squared $\\chi^2$ is commonly used to select the most significant features. \n",
    "\n",
    "We will use the <b> SelectKBest </b> class in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 111.52 , 1411.887,   17.605,   53.108, 2175.565,  127.669,\n",
       "          5.393,  181.304])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 attributes with the highest scores are: glucose, insulin, bmi and age \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[148. ,   0. ,  33.6,  50. ],\n",
       "       [ 85. ,   0. ,  26.6,  31. ],\n",
       "       [183. ,   0. ,  23.3,  32. ],\n",
       "       [ 89. ,  94. ,  28.1,  21. ],\n",
       "       [137. , 168. ,  43.1,  33. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Univariate selection using Chi-squared \n",
    "set_printoptions(precision=3)\n",
    "p_indians.head()\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 \n",
    "\n",
    "# feature selection (we select the 4 best)\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X,Y)\n",
    "print(\"Scores\")\n",
    "\n",
    "fit.scores_\n",
    "\n",
    "print(\"The 4 attributes with the highest scores are: glucose, insulin, bmi and age \")\n",
    "print()\n",
    "\n",
    "features=fit.transform(X)\n",
    "features[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Recursive Feature Elimination</h1>\n",
    "\n",
    "This is a very intuitive approach. It consist on recursively removing attributes and building a model with those atrributes remaining. It uses the model accuracy to identify which atrributes or combination of attributes contribute the most. \n",
    "\n",
    "We will use it with a logistic regression, but the choice of algorithm doesn't matter too much as long as your are consistent. \n",
    "\n",
    "Recursive Feature Elimination uses the <b>RFE </b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 3\n",
      "Selected features [ True False False False False  True  True False]\n",
      "Ranking of features [1 2 3 5 6 1 1 4]\n",
      "\n",
      "Top features seem to be pregnancies, bmi, and pedi(Diabetes Pedigree Function)\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "#Logistic regression\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "rfe = RFE(model, 3) #  we want to find the 3 top features\n",
    "fit = rfe.fit(X, Y)\n",
    "\n",
    "print(f'Number of features {fit.n_features_:d}')\n",
    "print(f'Selected features {fit.support_}')\n",
    "print(f'Ranking of features {fit.ranking_}')\n",
    "print()\n",
    "print(\"Top features seem to be pregnancies, bmi, and pedi(Diabetes Pedigree Function)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 1</font>\n",
    "\n",
    "For this and the next mission we will use data from Kaggle In concrete from the World University Rankings Competition https://www.kaggle.com/mylesoneill/world-university-rankings\n",
    "\n",
    "a) Using the Shanghai rankings find the top 3 most important features to explain them with both univariate and recursive (in recursive because we are using log regression create an output variable of being in the top 50 or not).\n",
    "<br><br>\n",
    "b) Same for the Times ranking. \n",
    "<br><br>\n",
    "c) Does it change if we choose the top 10 or top 100?\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writefile line is creating a new file called data_cleaning to later import the functions in other missions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_cleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_cleaning.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Clean shangai dataset function\n",
    "\n",
    "def shangai_clean(x):\n",
    "    # Read excel file and sort by total score\n",
    "    shangai = pd.read_excel(\"shanghaiData.xlsx\").sort_values(by = \"total_score\", ascending = False)\n",
    "        \n",
    "    # Filter by the latest year\n",
    "    shangai = shangai[shangai[\"year\"] == shangai[\"year\"].max()]\n",
    "    \n",
    "    # Simplify dataframe with only explanatory variables and drop null values\n",
    "    shangai.drop([\"world_rank\", \"university_name\", \"national_rank\", \"year\", \"total_score\"], axis = 1, inplace = True)\n",
    "    \n",
    "    # Drop null values\n",
    "    shangai.dropna(inplace = True)\n",
    "\n",
    "    # Code the top 50 universities\n",
    "    array_ref = (np.arange(len(shangai)) < x)\n",
    "    shangai[\"top_50\"] = array_ref\n",
    "    code = {True:1.0, False:0.0}\n",
    "    shangai[\"top_50\"] = shangai[\"top_50\"].map(code)\n",
    "    \n",
    "    # Return the array\n",
    "    return shangai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to data_cleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a data_cleaning.py\n",
    "\n",
    "# Clean the times dataset\n",
    "\n",
    "def times_clean(a):\n",
    "    \n",
    "    # Read the csv file and sort by total score ind descending order\n",
    "    times = pd.read_csv(\"timesData.csv\").sort_values(by = \"total_score\", ascending = False)\n",
    "    \n",
    "    # Drop null values from total score\n",
    "    times[\"total_score\"] = pd.to_numeric(times[\"total_score\"], errors = \"coerce\")\n",
    "    \n",
    "    # Filter by the latest year\n",
    "    times = times[times[\"year\"] == 2016] \n",
    "            \n",
    "    # Simplify the table by dropping non explanatory variables\n",
    "    times.drop([\"world_rank\", \"university_name\", \"country\", \"year\", \"total_score\"], axis = 1, inplace = True)\n",
    "    \n",
    "    # Times drop null values\n",
    "    times.dropna(inplace = True)\n",
    "        \n",
    "    # Convert all other columns to float type\n",
    "    times[\"international\"] = pd.to_numeric(times[\"international\"], errors = \"coerce\")\n",
    "    times[\"income\"] = pd.to_numeric(times[\"income\"], errors = \"coerce\") \n",
    "    times[\"female_male_ratio\"] = pd.to_numeric(times[\"female_male_ratio\"].apply(lambda d: d.split(\" : \")[0]), errors = \"coerce\")\n",
    "    times[\"international_students\"] = pd.to_numeric(times[\"international_students\"].apply(lambda d: d.split(\"%\")[0]), errors = \"coerce\")\n",
    "    \n",
    "    student_list = []\n",
    "    \n",
    "    for x in range(len(times)):\n",
    "        student_value = times[\"num_students\"].iloc[x].replace(\",\",\".\")\n",
    "        student_list.append(student_value)\n",
    "        \n",
    "    times[\"num_students\"] = pd.to_numeric(student_list, errors = \"coerce\")\n",
    "    \n",
    "    # Drop null values once again after converting all other columns to float \n",
    "    times.dropna(inplace = True)\n",
    "    \n",
    "    # Add a new column with the actual ranking\n",
    "    array_ref = (np.arange(len(times)) < a)\n",
    "    times[\"top_50\"] = array_ref\n",
    "    code = {True:1.0, False:0.0}\n",
    "    times[\"top_50\"] = times[\"top_50\"].map(code)\n",
    "    \n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_cleaning as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dc.times_clean(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating column printing function for recursive feature elimination\n",
    "\n",
    "def col_list(ranking, column_names):\n",
    "    var_s = ranking\n",
    "    top_cols = []\n",
    "    counter = 0\n",
    "    for x in var_s:\n",
    "        if var_s[counter] == 1:\n",
    "            top_cols.append(column_names[counter])\n",
    "        counter +=1\n",
    "    return top_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatating column printing function for univariate analysis\n",
    "\n",
    "def col_dic(scores):\n",
    "    import math\n",
    "    indices = np.arange(len(scores))\n",
    "    first_in = second_in = third_in = 0\n",
    "    first = second = third = -math.inf\n",
    "    for x in indices:\n",
    "        if scores[x] > first:\n",
    "            second = first\n",
    "            second_in = first_in\n",
    "            first = scores[x]\n",
    "            first_in = x\n",
    "        elif scores[x] > second:\n",
    "            third = second\n",
    "            third_in = second_in\n",
    "            second = scores[x]\n",
    "            second_in = x\n",
    "        elif scores[x] > third:\n",
    "            third = scores[x]\n",
    "            third_in = x\n",
    "    return {\"first\":first_in, \"second\":second_in, \"third\": third_in}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRecursive Feature Elimination\u001b[0m\n",
      "\n",
      "Number of features 3\n",
      "Selected features [False  True False  True False  True]\n",
      "Ranking of features [4 1 2 1 3 1]\n",
      "\n",
      "Top features are: award, ns, pcp\n",
      "\n",
      "\u001b[1mUnivariate Analysis\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3533.277,  8078.695,  2861.682,  2551.689,  599.288,  528.423])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top features are: pcp, pub, ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 100.000,  100.000,  100.000],\n",
       "       [ 40.700,  89.600,  80.100],\n",
       "       [ 68.200,  80.700,  60.600],\n",
       "       [ 65.100,  79.400,  66.100],\n",
       "       [ 77.100,  96.600,  50.800]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shangai top-50 analysis\n",
    "\n",
    "shangai_treat = dc.shangai_clean(50)\n",
    "shan_cols = shangai_treat.columns\n",
    "\n",
    "array = shangai_treat.values\n",
    "\n",
    "shan_x = array[:,0:6]\n",
    "shan_y = array[:,6]\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3)#  we want to find the 3 top features\n",
    "rec = rfe.fit(shan_x, shan_y)\n",
    "\n",
    "# Automate column outputs for RFE\n",
    " \n",
    "top_cols = col_list(rec.ranking_, shan_cols)\n",
    "    \n",
    "print('\\033[1m' + 'Recursive Feature Elimination' '\\033[0m')\n",
    "print()\n",
    "print(f'Number of features {rec.n_features_:d}')\n",
    "print(f'Selected features {rec.support_}')\n",
    "print(f'Ranking of features {rec.ranking_}')\n",
    "print()\n",
    "print(f\"Top features are: {top_cols[0]}, {top_cols[1]}, {top_cols[2]}\")\n",
    "\n",
    "# Run univariate analysis\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "uni = test.fit(shan_x,shan_y)\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Univariate Analysis' '\\033[0m')\n",
    "uni.scores_\n",
    "\n",
    "# Automate column outputs for univariate analysis\n",
    "\n",
    "cols = uni.scores_.argsort()[::1][:3]\n",
    "print(\"The top features are: \" + shan_cols[cols[0]] + \", \" + shan_cols[cols[1]] + \", \" + shan_cols[cols[2]]) \n",
    "\n",
    "features=uni.transform(shan_x)\n",
    "features[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRecursive Feature Elimination\u001b[0m\n",
      "\n",
      "Number of features 3\n",
      "Selected features [False False  True False False False  True False  True]\n",
      "Ranking of features [2 6 1 7 3 5 1 4 1]\n",
      "\n",
      "Top features are research, student_staff_ratio, and female_male_ratio\n",
      "\n",
      "\u001b[1mUnivariate Analysis\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.552e+03, 5.348e+02, 4.891e+03, 1.552e+03, 3.463e+02, 9.933e-02,\n",
       "       8.197e+01, 5.372e+02, 8.368e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top features are: research, teaching, citations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[95.6, 97.6, 99.8],\n",
       "       [86.5, 98.9, 98.8],\n",
       "       [92.5, 96.2, 99.9],\n",
       "       [88.2, 96.7, 97. ],\n",
       "       [89.4, 88.6, 99.7],\n",
       "       [85.1, 91.9, 99.3],\n",
       "       [83.3, 88.5, 96.7],\n",
       "       [77. , 95. , 91.1],\n",
       "       [85.7, 88.9, 99.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Times top-50 analysis\n",
    "\n",
    "times_treat = dc.times_clean(50)\n",
    "times_cols = times_treat.columns\n",
    "array = times_treat.values\n",
    "\n",
    "times_x = array[:,0:9]\n",
    "times_y = array[:,9]\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3) \n",
    "rec = rfe.fit(times_x, times_y)\n",
    "\n",
    "# Automate column outputs for RFE\n",
    " \n",
    "top_cols = col_list(rec.ranking_, times_cols)\n",
    "\n",
    "print('\\033[1m' + 'Recursive Feature Elimination' '\\033[0m')\n",
    "print()\n",
    "print(f'Number of features {rec.n_features_:d}')\n",
    "print(f'Selected features {rec.support_}')\n",
    "print(f'Ranking of features {rec.ranking_}')\n",
    "print()\n",
    "print(f\"Top features are {top_cols[0]}, {top_cols[1]}, and {top_cols[2]}\")\n",
    "\n",
    "# Run univariate analysis\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "uni = test.fit(times_x, times_y)\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Univariate Analysis' '\\033[0m')\n",
    "uni.scores_\n",
    "\n",
    "cols = col_dic(uni.scores_)    \n",
    "print(\"The top features are: \" + times_cols[cols[\"first\"]] + \", \" + times_cols[cols[\"second\"]] + \", \" + times_cols[cols[\"third\"]]) \n",
    "\n",
    "features=uni.transform(times_x)\n",
    "features[0:9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Does it change if we choose the top 10 or top 100? Since shangai only has 100 rows after dropping null values from \n",
    "# the total score, we are going to test this with the times dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRecursive Feature Elimination\u001b[0m\n",
      "\n",
      "Number of features 3\n",
      "Selected features [ True False  True False  True False]\n",
      "Ranking of features [1 4 1 3 1 2]\n",
      "\n",
      "Top features are alumni, hici, and pub\n",
      "\n",
      "\u001b[1mUnivariate Analysis\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3839.867, 7499.15 , 1446.554, 1397.945,  168.597,  681.022])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top features are: award, alumni, hici\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100. , 100. , 100. ],\n",
       "       [ 40.7,  89.6,  80.1],\n",
       "       [ 68.2,  80.7,  60.6],\n",
       "       [ 65.1,  79.4,  66.1],\n",
       "       [ 77.1,  96.6,  50.8],\n",
       "       [ 53.3,  93.4,  57.1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shangai top-10 analysis\n",
    "\n",
    "shangai_treat = dc.shangai_clean(10)\n",
    "shangai_cols = shangai_treat.columns\n",
    "shangai_array_10 = shangai_treat.values\n",
    "\n",
    "shangai_x10 = shangai_array_10[:,0:6]\n",
    "shangai_y10 = shangai_array_10[:,6]\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3) \n",
    "rec = rfe.fit(shangai_x10, shangai_y10)\n",
    "\n",
    "# Automate column outputs for RFE\n",
    " \n",
    "top_cols = col_list(rec.ranking_, shangai_cols)\n",
    "\n",
    "print('\\033[1m' + 'Recursive Feature Elimination' '\\033[0m')\n",
    "print()\n",
    "print(f'Number of features {rec.n_features_:d}')\n",
    "print(f'Selected features {rec.support_}')\n",
    "print(f'Ranking of features {rec.ranking_}')\n",
    "print()\n",
    "print(f\"Top features are {top_cols[0]}, {top_cols[1]}, and {top_cols[2]}\")\n",
    "\n",
    "# Run univariate analysis\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "uni = test.fit(shangai_x10, shangai_y10)\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Univariate Analysis' '\\033[0m')\n",
    "uni.scores_\n",
    "\n",
    "cols = col_dic(uni.scores_)    \n",
    "print(\"The top features are: \" + shangai_cols[cols[\"first\"]] + \", \" + shangai_cols[cols[\"second\"]] + \", \" + shangai_cols[cols[\"third\"]]) \n",
    "\n",
    "features=uni.transform(shangai_x10)\n",
    "features[0:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRecursive Feature Elimination\u001b[0m\n",
      "\n",
      "Number of features 3\n",
      "Selected features [ True  True  True False False False]\n",
      "Ranking of features [1 1 1 3 4 2]\n",
      "\n",
      "Top features are alumni, award, and hici\n",
      "\n",
      "\u001b[1mUnivariate Analysis\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3589.923, 7203.251, 2934.493, 2328.666,  665.928,  577.754])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top features are: award, alumni, hici\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[100. , 100. , 100. ],\n",
       "       [ 40.7,  89.6,  80.1],\n",
       "       [ 68.2,  80.7,  60.6],\n",
       "       [ 65.1,  79.4,  66.1],\n",
       "       [ 77.1,  96.6,  50.8],\n",
       "       [ 53.3,  93.4,  57.1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shangai top-100 analysis\n",
    "\n",
    "shangai_treat = dc.shangai_clean(100)\n",
    "shangai_cols = shangai_treat.columns\n",
    "shangai_array_100 = shangai_treat.values\n",
    "\n",
    "shangai_x100 = shangai_array_100[:,0:6]\n",
    "shangai_y100 = shangai_array_100[:,6]\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3) \n",
    "rec = rfe.fit(shangai_x100, shangai_y100)\n",
    "\n",
    "# Automate column outputs for RFE\n",
    " \n",
    "top_cols = col_list(rec.ranking_, shangai_cols)\n",
    "\n",
    "print('\\033[1m' + 'Recursive Feature Elimination' '\\033[0m')\n",
    "print()\n",
    "print(f'Number of features {rec.n_features_:d}')\n",
    "print(f'Selected features {rec.support_}')\n",
    "print(f'Ranking of features {rec.ranking_}')\n",
    "print()\n",
    "print(f\"Top features are {top_cols[0]}, {top_cols[1]}, and {top_cols[2]}\")\n",
    "\n",
    "# Run univariate analysis\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "uni = test.fit(shangai_x100, shangai_y100)\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Univariate Analysis' '\\033[0m')\n",
    "uni.scores_\n",
    "\n",
    "cols = col_dic(uni.scores_)    \n",
    "print(\"The top features are: \" + shangai_cols[cols[\"first\"]] + \", \" + shangai_cols[cols[\"second\"]] + \", \" + shangai_cols[cols[\"third\"]]) \n",
    "\n",
    "features=uni.transform(shangai_x100)\n",
    "features[0:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRecursive Feature Elimination\u001b[0m\n",
      "\n",
      "Number of features 3\n",
      "Selected features [False False  True False False False  True False  True]\n",
      "Ranking of features [2 5 1 4 6 3 1 7 1]\n",
      "\n",
      "Top features are research, student_staff_ratio, and female_male_ratio\n",
      "\n",
      "\u001b[1mUnivariate Analysis\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 966.246,  217.918, 1522.134,  410.647,  130.602,   55.884,\n",
       "         53.895,  247.092,   14.761])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top features are: research, teaching, citations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[95.6, 97.6, 99.8],\n",
       "       [86.5, 98.9, 98.8],\n",
       "       [92.5, 96.2, 99.9],\n",
       "       [88.2, 96.7, 97. ],\n",
       "       [89.4, 88.6, 99.7],\n",
       "       [85.1, 91.9, 99.3],\n",
       "       [83.3, 88.5, 96.7],\n",
       "       [77. , 95. , 91.1],\n",
       "       [85.7, 88.9, 99.2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Times top-10 analysis\n",
    "\n",
    "times_treat = dc.times_clean(10)\n",
    "times_cols = times_treat.columns\n",
    "array_10 = times_treat.values\n",
    "\n",
    "times_x10 = array_10[:,0:9]\n",
    "times_y10 = array_10[:,9]\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3) \n",
    "rec = rfe.fit(times_x10, times_y10)\n",
    "\n",
    "# Automate column outputs for RFE\n",
    " \n",
    "top_cols = col_list(rec.ranking_, times_cols)\n",
    "\n",
    "print('\\033[1m' + 'Recursive Feature Elimination' '\\033[0m')\n",
    "print()\n",
    "print(f'Number of features {rec.n_features_:d}')\n",
    "print(f'Selected features {rec.support_}')\n",
    "print(f'Ranking of features {rec.ranking_}')\n",
    "print()\n",
    "print(f\"Top features are {top_cols[0]}, {top_cols[1]}, and {top_cols[2]}\")\n",
    "\n",
    "# Run univariate analysis\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "uni = test.fit(times_x10, times_y10)\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Univariate Analysis' '\\033[0m')\n",
    "print()\n",
    "uni.scores_\n",
    "\n",
    "cols = col_dic(uni.scores_)    \n",
    "print(\"The top features are: \" + times_cols[cols[\"first\"]] + \", \" + times_cols[cols[\"second\"]] + \", \" + times_cols[cols[\"third\"]]) \n",
    "\n",
    "features=uni.transform(times_x10)\n",
    "features[0:9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRecursive Feature Elimination\u001b[0m\n",
      "\n",
      "Number of features 3\n",
      "Selected features [False False  True  True False False False False  True]\n",
      "Ranking of features [5 6 1 1 4 7 2 3 1]\n",
      "\n",
      "Top features are research, citations, and female_male_ratio\n",
      "\n",
      "\u001b[1mUnivariate Analysis\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.676e+03, 1.005e+03, 5.521e+03, 2.761e+03, 5.094e+02, 5.793e+01,\n",
       "       6.508e+01, 7.683e+02, 6.238e-01])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top features are: research, citations, teaching\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[95.6, 97.6, 99.8],\n",
       "       [86.5, 98.9, 98.8],\n",
       "       [92.5, 96.2, 99.9],\n",
       "       [88.2, 96.7, 97. ],\n",
       "       [89.4, 88.6, 99.7],\n",
       "       [85.1, 91.9, 99.3],\n",
       "       [83.3, 88.5, 96.7],\n",
       "       [77. , 95. , 91.1],\n",
       "       [85.7, 88.9, 99.2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Times top-100 analysis\n",
    "\n",
    "times_treat = dc.times_clean(100)\n",
    "times_cols = times_treat.columns\n",
    "array_100 = times_treat.values\n",
    "\n",
    "times_x100 = array_100[:,0:9]\n",
    "times_y100 = array_100[:,9]\n",
    "\n",
    "# Run Logistic Regression\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(model, 3) \n",
    "rec = rfe.fit(times_x100, times_y100)\n",
    "\n",
    "# Automate column outputs for RFE\n",
    " \n",
    "top_cols = col_list(rec.ranking_, times_cols)\n",
    "\n",
    "print('\\033[1m' + 'Recursive Feature Elimination' '\\033[0m')\n",
    "print()\n",
    "print(f'Number of features {rec.n_features_:d}')\n",
    "print(f'Selected features {rec.support_}')\n",
    "print(f'Ranking of features {rec.ranking_}')\n",
    "print()\n",
    "print(f\"Top features are {top_cols[0]}, {top_cols[1]}, and {top_cols[2]}\")\n",
    "\n",
    "# Run univariate analysis\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "uni = test.fit(times_x100, times_y100)\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Univariate Analysis' '\\033[0m')\n",
    "print()\n",
    "uni.scores_\n",
    "\n",
    "cols = col_dic(uni.scores_)    \n",
    "print(\"The top features are: \" + times_cols[cols[\"first\"]] + \", \" + times_cols[cols[\"second\"]] + \", \" + times_cols[cols[\"third\"]]) \n",
    "\n",
    "features=uni.transform(times_x100)\n",
    "features[0:9,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we can see for the times datasets, scores and the most important features have changed for the top-10 or top-100.\n",
      "\n",
      "This is due to the fact that the output variable is different for top-10 and top-100.\n",
      "\n",
      "The factors determining whether a university is elite (top-10) can be different from the factors determining whether a\n",
      "university is very good (top-100).\n",
      "\n",
      "Hence, different variables should explain the variance in the different output variable.\n",
      "\n",
      "Also, there is no reason to believe that this should change for the shangai dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"As we can see for the times datasets, scores and the most important features have changed for the top-10 or top-100.\")\n",
    "print()\n",
    "print(\"This is due to the fact that the output variable is different for top-10 and top-100.\")\n",
    "print()\n",
    "print(\"The factors determining whether a university is elite (top-10) can be different from the factors determining whether a\") \n",
    "print(\"university is very good (top-100).\")\n",
    "print()\n",
    "print(\"Hence, different variables should explain the variance in the different output variable.\")\n",
    "print()\n",
    "print(\"Also, there is no reason to believe that this should change for the shangai dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Principal Component Analysis</h1>\n",
    "\n",
    "Principal Component Analysis is a data reduction technique using linear algebra. The idea here is to \"compress\" several dimensions into pricipal components. \n",
    "\n",
    "One problem of PCA is the explainability. Once you compressed the attributes into principal components you can no longer to refer them individually establishing causality links or relationships. \n",
    "\n",
    "A property of PCA is that you can choose the number of dimensions or principal components. In our example we will select 3 principal components. \n",
    "\n",
    "For Principal Component Analysis you use the <b>PCA</b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: [0.889 0.062 0.026]\n",
      "\n",
      "Principal Components have little resemblance to the source data attributes\n",
      "\n",
      "[[-0.002  0.098  0.016  0.061  0.993  0.014  0.001 -0.004]\n",
      " [-0.023 -0.972 -0.142  0.058  0.095 -0.047 -0.001 -0.140]\n",
      " [-0.022  0.143 -0.922 -0.307  0.021 -0.132 -0.001 -0.125]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_fit = pca.fit(X)\n",
    "\n",
    "print(f\"Explained variance: {pca_fit.explained_variance_ratio_}\")\n",
    "print()\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "print(\"Principal Components have little resemblance to the source data attributes\")\n",
    "print()\n",
    "print(pca_fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First component explains 0.889 of the variance, second explains 0.062, third explains 0.026\n",
    "# First row is how the first component was formed, second row how the second component was formed, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Importance </h1>\n",
    "\n",
    "One of the added features of tree based algorithms is that they can be used to estimate the importance of each feature and use it to refine the model to different levels depending on where we want to situate ourselves in the tension between explainability and accuracy. \n",
    "\n",
    "In this example we are going to use the ExtraTreesClassifier, but the technique is commonly used in all tree algoritms. \n",
    "\n",
    "For this example of assessing feature importance with trees we will use the <b>ExtraTreesClassifier</b> class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  pressure  skin  insulin   bmi   pedi  age  outcome\n",
       "0            6      148        72    35        0  33.6  0.627   50        1\n",
       "1            1       85        66    29        0  26.6  0.351   31        0\n",
       "2            8      183        64     0        0  23.3  0.672   32        1\n",
       "3            1       89        66    23       94  28.1  0.167   21        0\n",
       "4            0      137        40    35      168  43.1  2.288   33        1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.112  0.232  0.100  0.080  0.072  0.141  0.119  0.142]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "p_indians.head()\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X,Y)\n",
    "\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color=\"red\" size=6>Mission 2</font>\n",
    "\n",
    "a) Using the Shangai Data find the top attributes with a tree classifier for top-10, top-50 and top-100.  \n",
    "<br>\n",
    "b) Same for the Times ranking. \n",
    "<br><br>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShangai dataset with top-100 universities\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.108  0.231  0.258  0.182  0.132  0.089]\n",
      "\n",
      "The top 3 features are: pcp, alumni, pub\n",
      "\n",
      "\u001b[1mShangai dataset with top-50 universities\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.106  0.231  0.215  0.256  0.125  0.067]\n",
      "\n",
      "The top 3 features are: pcp, alumni, pub\n",
      "\n",
      "\u001b[1mShangai dataset with top-10 universities\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.202  0.366  0.113  0.119  0.039  0.161]\n",
      "\n",
      "The top 3 features are: pub, hici, ns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a) Using the Shangai Data find the top attributes with a tree classifier for top-10 and top-50.\n",
    "\n",
    "array_100 = dc.shangai_clean(100).values\n",
    "array_50 = dc.shangai_clean(50).values\n",
    "array_10 = dc.shangai_clean(10).values\n",
    "\n",
    "x_100 = array_100[:,0:6]\n",
    "y_100 = array_100[:,6]\n",
    "\n",
    "x_50 = array_50[:,0:6]\n",
    "y_50 = array_50[:,6]\n",
    "\n",
    "x_10 = array_10[:,0:6]\n",
    "y_10 = array_10[:,6]\n",
    "\n",
    "\n",
    "# Model with top 100 estimators\n",
    "\n",
    "print('\\033[1m' + 'Shangai dataset with top-100 universities' '\\033[0m')\n",
    "\n",
    "model_100 = ExtraTreesClassifier(n_estimators=100)\n",
    "model_100.fit(x_100,y_100)\n",
    "\n",
    "print(model_100.feature_importances_)\n",
    "indices_100 = model_100.feature_importances_.argsort()[::1][:3]\n",
    "print()\n",
    "print(\"The top 3 features are: \" + shan_cols[indices_100[0]] + \", \" + shan_cols[indices_100[1]] + \", \" + shan_cols[indices_100[2]])\n",
    "print()\n",
    "\n",
    "\n",
    "# Model with top 50 estimators\n",
    "\n",
    "print('\\033[1m' + 'Shangai dataset with top-50 universities' '\\033[0m')\n",
    "\n",
    "model_50 = ExtraTreesClassifier(n_estimators=100)\n",
    "model_50.fit(x_50,y_50)\n",
    "\n",
    "print(model_50.feature_importances_)\n",
    "indices_50 = model_50.feature_importances_.argsort()[::1][:3]\n",
    "print()\n",
    "print(\"The top 3 features are: \" + shan_cols[indices_50[0]] + \", \" + shan_cols[indices_50[1]] + \", \" + shan_cols[indices_50[2]])\n",
    "print()\n",
    "\n",
    "\n",
    "# Model with top 10 estimators\n",
    "\n",
    "print('\\033[1m' + 'Shangai dataset with top-10 universities' '\\033[0m')\n",
    "\n",
    "model_10 = ExtraTreesClassifier(n_estimators=100)\n",
    "model_10.fit(x_10,y_10)\n",
    "\n",
    "print(model_10.feature_importances_)\n",
    "indices_10 = model_10.feature_importances_.argsort()[::1][:3]\n",
    "print()\n",
    "print(\"The top 3 features are: \" + shan_cols[indices_10[0]] + \", \" + shan_cols[indices_10[1]] + \", \" + shan_cols[indices_10[2]])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTimes dataset with top-100 universities\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 features are: female_male_ratio, student_staff_ratio, num_students\n",
      "\n",
      "[ 0.325  0.059  0.306  0.151  0.041  0.026  0.025  0.044  0.024]\n",
      "\n",
      "\u001b[1mTimes dataset with top-50 universities\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 features are: student_staff_ratio, female_male_ratio, num_students\n",
      "\n",
      "[ 0.359  0.028  0.386  0.095  0.036  0.019  0.017  0.041  0.018]\n",
      "\n",
      "\u001b[1mTimes dataset with top-10 universities\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 3 features are: income, student_staff_ratio, international\n",
      "\n",
      "[ 0.325  0.059  0.306  0.151  0.041  0.026  0.025  0.044  0.024]\n"
     ]
    }
   ],
   "source": [
    "# b) Same for the Times ranking.\n",
    "\n",
    "array_100 = dc.times_clean(100).values\n",
    "array_50 = dc.times_clean(50).values\n",
    "array_10 = dc.times_clean(10).values\n",
    "\n",
    "x_100 = array_100[:,0:9]\n",
    "y_100 = array_100[:,9]\n",
    "\n",
    "x_50 = array_50[:,0:9]\n",
    "y_50 = array_50[:,9]\n",
    "\n",
    "x_10 = array_10[:,0:9]\n",
    "y_10 = array_10[:,9]\n",
    "\n",
    "# Model with top 100 estimators\n",
    "\n",
    "print('\\033[1m' + 'Times dataset with top-100 universities' '\\033[0m')\n",
    "\n",
    "model_100 = ExtraTreesClassifier(n_estimators=100)\n",
    "model_100.fit(x_100,y_100)\n",
    "\n",
    "indices_100 = model_100.feature_importances_.argsort()[::1][:3]\n",
    "print(\"The top 3 features are: \" + times_cols[indices_100[0]] + \", \" + times_cols[indices_100[1]] + \", \" + times_cols[indices_100[2]])\n",
    "print()\n",
    "\n",
    "print(model_100.feature_importances_)\n",
    "\n",
    "# Model with top 50 estimators\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Times dataset with top-50 universities' '\\033[0m')\n",
    "\n",
    "model_50 = ExtraTreesClassifier(n_estimators=100)\n",
    "model_50.fit(x_50,y_50)\n",
    "\n",
    "indices_50 = model_50.feature_importances_.argsort()[::1][:3]\n",
    "print(\"The top 3 features are: \" + times_cols[indices_50[0]] + \", \" + times_cols[indices_50[1]] + \", \" + times_cols[indices_50[2]])\n",
    "print()\n",
    "\n",
    "print(model_50.feature_importances_)\n",
    "\n",
    "# Model with top 10 estimators\n",
    "\n",
    "print()\n",
    "print('\\033[1m' + 'Times dataset with top-10 universities' '\\033[0m')\n",
    "\n",
    "model_10 = ExtraTreesClassifier(n_estimators=100)\n",
    "model_10.fit(x_10,y_10)\n",
    "\n",
    "indices_10 = model_10.feature_importances_.argsort()[::1][:3]\n",
    "print(\"The top 3 features are: \" + times_cols[indices_10[0]] + \", \" + times_cols[indices_10[1]] + \", \" + times_cols[indices_10[2]])\n",
    "print()\n",
    "\n",
    "print(model_100.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
